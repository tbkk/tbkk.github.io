---
layout:     post
title:      微服务之限流
subtitle:   白话限流
date:       2019-12-10
author:     TBKK
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 微服务
---

# 限流算法
对于一个大的系统，限流是保证整个系统稳定的必要手段之一。意思是，你可以请求是吧，下次再试，但是系统不允许雪崩。

## 令牌桶算法
大家理解一下进高速公路收费的模型就理解了，进高速公路的速度取决于收费员派发路卡的速度，路卡就相当于令牌，这就是令牌桶算法。

## 漏桶算法

就是有个缓冲区，多了就丢弃

## 滑动窗口算法
### 限流滑动窗口
将时间片分割的足够小，1ms作为1个小窗口，多个连续的窗口在一起就是一个窗口
![image](http://www.qinxinfeng.com/img/others/windows-1.jpg)
每一个格式表示一个固定的时间（比如1s），每个格子一个计数器，我们要获取前5s的请求量，就是对当前时间片i ~ i-4的时间片上计数器进行累加。
滑窗模式通常适用于对某一资源的保护的需求上，如对db的保护，对某一服务的调用的控制上。 
代码如下：

```java
public class SlidingWindow {  
  
    /* 循环队列 */  
    private volatile AtomicInteger[] timeSlices;  
    /* 队列的总长度  */  
    private volatile int timeSliceSize;  
    /* 每个时间片的时长 */  
    private volatile int timeMillisPerSlice;  
    /* 窗口长度 */  
    private volatile int windowSize;  
      
    /* 当前所使用的时间片位置 */  
    private AtomicInteger cursor = new AtomicInteger(0);  
      
    public SlidingWindow(int timeMillisPerSlice, int windowSize) {  
        this.timeMillisPerSlice = timeMillisPerSlice;  
        this.windowSize = windowSize;  
        // 保证存储在至少两个window  
        this.timeSliceSize = windowSize * 2 + 1;  
    }  
      
    /** 
     * 初始化队列，由于此初始化会申请一些内容空间，为了节省空间，延迟初始化 
     */  
    private void initTimeSlices() {  
        if (timeSlices != null) {  
            return;  
        }  
        // 在多线程的情况下，会出现多次初始化的情况，没关系  
        // 我们只需要保证，获取到的值一定是一个稳定的，所有这里使用先初始化，最后赋值的方法  
        AtomicInteger[] localTimeSlices = new AtomicInteger[timeSliceSize];  
        for (int i = 0; i < timeSliceSize; i++) {  
            localTimeSlices[i] = new AtomicInteger(0);  
        }  
        timeSlices = localTimeSlices;  
    }  
      
    private int locationIndex() {  
        long time = System.currentTimeMillis();  
        return (int) ((time / timeMillisPerSlice) % timeSliceSize);  
    }  
      
    /** 
     * <p>对时间片计数+1，并返回窗口中所有的计数总和 
     * <p>该方法只要调用就一定会对某个时间片进行+1 
     *  
     * @return 
     */  
    public int incrementAndSum() {  
        initTimeSlices();  
        int index = locationIndex();  
        int sum = 0;  
        // cursor等于index，返回true  
        // cursor不等于index，返回false，并会将cursor设置为index  
        int oldCursor = cursor.getAndSet(index);  
        if (oldCursor == index) {  
            // 在当前时间片里继续+1  
            sum += timeSlices[index].incrementAndGet();  
        } else {  
            // 可能有其他thread已经置过1，问题不大  
            timeSlices[index].set(1);  
            // 清零，访问量不大时会有时间片跳跃的情况  
            clearBetween(oldCursor, index);  
            // sum += 0;  
        }  
        for (int i = 1; i < windowSize; i++) {  
            sum += timeSlices[(index - i + timeSliceSize) % timeSliceSize].get();  
        }  
        return sum;  
    }  
      
    /** 
     * 判断是否允许进行访问，未超过阈值的话才会对某个时间片+1 
     *  
     * @param threshold 
     * @return 
     */  
    public boolean allow(int threshold) {  
        initTimeSlices();  
        int index = locationIndex();  
        int sum = 0;  
        // cursor不等于index，将cursor设置为index  
        int oldCursor = cursor.getAndSet(index);  
        if (oldCursor != index) {  
            // 可能有其他thread已经置过1，问题不大  
            timeSlices[index].set(0);  
            // 清零，访问量不大时会有时间片跳跃的情况  
            clearBetween(oldCursor, index);  
        }  
        for (int i = 1; i < windowSize; i++) {  
            sum += timeSlices[(index - i + timeSliceSize) % timeSliceSize].get();  
        }  
          
        // 阈值判断  
        if (sum <= threshold) {  
            // 未超过阈值才+1  
            sum += timeSlices[index].incrementAndGet();  
            return true;  
        }  
        return false;  
    }  
      
    /** 
     * <p>将fromIndex~toIndex之间的时间片计数都清零 
     * <p>极端情况下，当循环队列已经走了超过1个timeSliceSize以上，这里的清零并不能如期望的进行 
     *  
     * @param fromIndex 不包含 
     * @param toIndex 不包含 
     */  
    private void clearBetween(int fromIndex, int toIndex) {  
        for (int index = (fromIndex + 1) % timeSliceSize; index != toIndex; index = (index + 1) % timeSliceSize) {  
            timeSlices[index].set(0);  
        }  
    }  
      
}  
```

### TCP滑动窗口
关于TCP的滑动窗口，其本质上实际是对于缓冲区大小的反馈。

通信中每次ACK，都把自身缓存区的大小返回给发送端，这样发送端就能根据缓存大小来发送消息量了。以此来做流控。


# 限流工具
## Sentinel限流
Sentinel的限流算法，就是用的滑动窗口算法。主要用到的设计模式是责任链模式。责任链模式在很多中间件都使用到了，比如Netty，
具体可以看一下我的文章《间件常用的设计模式-责任链模式》
```java
public class DefaultSlotChainBuilder implements SlotChainBuilder {
    @Override
    public ProcessorSlotChain build() {
        ProcessorSlotChain chain = new DefaultProcessorSlotChain();
        chain.addLast(new NodeSelectorSlot());
        chain.addLast(new ClusterBuilderSlot());
        chain.addLast(new LogSlot());
        chain.addLast(new StatisticSlot());
        chain.addLast(new SystemSlot());
        chain.addLast(new AuthoritySlot());
        chain.addLast(new FlowSlot());
        chain.addLast(new DegradeSlot());

        return chain;
    }
}
```
在 Sentinel 里面，所有的资源都对应一个资源名称（resourceName），每次资源调用都会创建一个 Entry 对象。Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 SphU API 显式创建。Entry 创建的时候，同时也会创建一系列功能插槽（slot chain），这些插槽有不同的职责，例如:

* NodeSelectorSlot ：收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级；
* ClusterBuilderSlot ：用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据；
* StatisticSlot ：用于记录、统计不同纬度的 runtime 指标监控信息；
* SystemSlot ：通过系统的状态，例如 load1 等，来控制总的入口流量；
* AuthoritySlot ：根据配置的黑白名单和调用来源信息，来做黑白名单控制；
* FlowSlot ：用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制；
* DegradeSlot ：通过统计信息以及预设的规则，来做熔断降级；

## Sentinel VS Hystrix（以下摘录自sentinel官方文档）
不得不说，当前环境下使用Hystrix的公司还是很多，但是Hystrix是Netflix的一款开源限流组件，官方宣布停止在开源版本上提供新功能，还是有点可惜的。
Hystrix官方推荐使用Resilience4j。不过这个当前使用的公司并不是很多，具体还有待实践。

先来看一下 [Hystrix](https://github.com/Netflix/Hystrix/wiki) 的官方介绍：

> Hystrix is a library that helps you control the interactions between these distributed services by adding latency tolerance and fault tolerance logic. Hystrix does this by isolating points of access between the services, stopping cascading failures across them, and providing fallback options, all of which improve your system’s overall resiliency.

而 Sentinel 的侧重点在于：

- 多样化的流量控制
- 熔断降级
- 系统负载保护
- 实时监控和控制台



可以看到两者解决的问题还是有比较大的不同的，下面我们来分别对比一下。

## 共同特性

### 资源模型和执行模型上的对比

Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（`HystrixCommand` / `HystrixObservableCommand`），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。

Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流/降级/负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种：

- try-catch 方式（通过 `SphU.entry(...)`），用户在 catch 块中执行异常处理 / fallback
- if-else 方式（通过 `SphO.entry(...)`），当返回 false 时执行异常处理 / fallback

未来 Sentinel 还会引入基于注解的资源定义方式，同时可以通过注解参数指定异常处理函数和 fallback 函数。

Sentinel 提供[多样化的规则配置方式](https://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95)。除了直接通过 `loadRules` API 将规则注册到内存态之外，用户还可以注册各种外部数据源来提供动态的规则。用户可以根据系统当前的实时情况去动态地变更规则配置，数据源会将变更推送至 Sentinel 并即时生效。

### 隔离设计上的对比

隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。

但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。

Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错。但缺点是无法对慢调用自动进行降级，只能等待客户端自己超时，因此仍然可能会出现级联阻塞的情况。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。

### 熔断降级对比

Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。

### 实时指标统计实现对比

Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功/失败/超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。

Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 `LeapArray` 的滑动窗口，后续根据需要可能会引入 reactive stream 等实现。

## Sentinel 的特色

除了之前提到的两者的共同特性之外，Sentinel 还提供以下的特色功能：

### 轻量级、高性能

Sentinel 作为一个功能完备的高可用流量管控组件，其核心 `sentinel-core` 没有任何多余依赖，打包后只有不到 200 KB，非常轻量级。开发者可以放心地引入 `sentinel-core` 而不需担心依赖问题。同时，Sentinel 提供了多种扩展点，用户可以很方便地根据需求去进行扩展，并且无缝地切合到 Sentinel 中。

引入 Sentinel 带来的性能损耗非常小。只有在业务单机量级超过 25W QPS 的时候才会有一些显著的影响（5% - 10% 左右），单机 QPS 不太大的时候损耗几乎可以忽略不计。

### 流量控制

Sentinel 可以针对不同的调用关系，以不同的运行指标（如 QPS、并发调用数、系统负载等）为基准，对资源调用进行流量控制，将随机的请求调整成合适的形状。

Sentinel 支持多样化的流量整形策略，在 QPS 过高的时候可以自动将流量调整成合适的形状。常用的有：

- 直接拒绝模式：即超出的请求直接拒绝。

- 慢启动预热模式：当流量激增的时候，控制流量通过的速率，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。

![WarmUp](https://github.com/alibaba/Sentinel/wiki/image/warmup.gif)

- 匀速器模式：利用 Leaky Bucket 算法实现的匀速模式，严格控制了请求通过的时间间隔，同时堆积的请求将会排队，超过超时时长的请求直接被拒绝。

![Uniform rate (Virtual Queue)](https://github.com/alibaba/Sentinel/wiki/image/uniform-speed-queue.png)

Sentinel 还支持[基于调用关系的限流](https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6#%E5%9F%BA%E4%BA%8E%E8%B0%83%E7%94%A8%E5%85%B3%E7%B3%BB%E7%9A%84%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6)，包括基于调用方限流、基于调用链入口限流、关联流量限流等，依托于 Sentinel 强大的调用链路统计信息，可以提供精准的不同维度的限流。

目前 Sentinel 对异步调用链路的支持还不是很好，后续版本会着重改善支持异步调用。

### 系统负载保护

Sentinel 对系统的维度提供保护，负载保护算法借鉴了 TCP BBR 的思想。当系统负载较高的时候，如果仍持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。

![BBR 经典图](https://camo.githubusercontent.com/5b1fd9b8d18c504f0c910c00b2b58876ab4eb452/687474703a2f2f617461322d696d672e636e2d68616e677a686f752e696d672d7075622e616c6979756e2d696e632e636f6d2f62313766326563396132346261376639373033643034626334343239633637342e6a7067)

### 实时监控与控制面板

Sentinel 提供 HTTP API 用于获取[实时的监控信息](https://github.com/alibaba/Sentinel/wiki/%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7)，如调用链路统计信息、簇点信息、规则信息等。如果用户正在使用 Spring Boot/Spring Cloud 并使用了 [Sentinel Spring Cloud Starter](https://github.com/spring-cloud-incubator/spring-cloud-alibabacloud)，还可以方便地通过其暴露的 Actuator Endpoint 来获取运行时的一些信息，如动态规则等。未来 Sentinel 还会支持标准化的指标监控 API，可以方便地整合各种监控系统和可视化系统，如 Prometheus、Grafana 等。

[Sentinel 控制台](https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0)（Dashboard）提供了机器发现、配置规则、查看实时监控、查看调用链路信息等功能，使得用户可以非常方便地去查看监控和进行配置。

![Sentinel Dashboard](https://github.com/alibaba/Sentinel/wiki/image/dashboard.png)

### 生态

Sentinel 目前已经针对 Servlet、Dubbo、Spring Boot/Spring Cloud、gRPC 等进行了适配，用户只需引入相应依赖并进行简单配置即可非常方便地享受 Sentinel 的高可用流量防护能力。未来 Sentinel 还会对更多常用框架进行适配，并且会为 Service Mesh 提供集群流量防护的能力。

## 总结

最后用表格来进行对比总结：


|  | Sentinel | Hystrix |
| -------- | -------- | -------- |
| 隔离策略     | 信号量隔离     | 线程池隔离/信号量隔离     |
| 熔断降级策略    | 基于响应时间或失败比率     | 基于失败比率     |
| 实时指标实现    | 滑动窗口     | 滑动窗口（基于 RxJava）     |
| 规则配置    | 支持多种数据源     | 支持多种数据源     |
| 扩展性    | 多个扩展点     | 插件的形式     |
| 基于注解的支持    | 即将支持     | 支持     |
| 限流    | 基于 QPS，支持基于调用关系的限流    | 不支持     |
| 流量整形    | 支持慢启动、匀速器模式     | 不支持     |
| 系统负载保护    | 支持     | 不支持     |
| 控制台  | 开箱即用，可配置规则、查看秒级监控、机器发现等     | 不完善     |
| 常见框架的适配    | Servlet、Spring Cloud、Dubbo、gRPC 等     | Servlet、Spring Cloud Netflix  |

## Nginx限流
配置文件即可实现限流，这里不多做介绍了，各位可以自己baidu
